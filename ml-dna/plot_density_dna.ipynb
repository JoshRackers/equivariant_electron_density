{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch_geometric\n",
    "\n",
    "from utils import get_iso_permuted_dataset\n",
    "from utils import flatten_list\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print (device)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "#torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './2mer-test.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-360175883dd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mppp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./data/p_s_only_augccpvdz_density.out\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_iso_permuted_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_iso\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhhh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc_iso\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mccc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_iso\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnnn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mo_iso\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mooo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp_iso\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mppp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/bdna/ml-dna-gitupload/utils.py\u001b[0m in \u001b[0;36mget_iso_permuted_dataset\u001b[0;34m(picklefile, amberFlag, **atm_iso)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Isolated atom type not found. Use kwargs \\\"h_iso\\\", \\\"c_iso\\\", etc.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mmolecule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpicklefile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmolecule\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# z is atomic number- may want to make 1,0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './2mer-test.pkl'"
     ]
    }
   ],
   "source": [
    "# first, get dataset\n",
    "datafile = \"./2mer-test.pkl\"\n",
    "\n",
    "hhh = \"./data/h_s_only_augccpvdz_density.out\"\n",
    "ooo = \"./data/o_s_only_augccpvdz_density.out\"\n",
    "ccc = \"./data/c_s_only_augccpvdz_density.out\"\n",
    "nnn = \"./data/n_s_only_augccpvdz_density.out\"\n",
    "ppp = \"./data/p_s_only_augccpvdz_density.out\"\n",
    "\n",
    "dataset = get_iso_permuted_dataset(datafile,h_iso=hhh,c_iso=ccc,n_iso=nnn,o_iso=ooo,p_iso=ppp)\n",
    "\n",
    "split = 500\n",
    "b = 1\n",
    "loader = torch_geometric.data.DataLoader(dataset, batch_size=b, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (layers): ModuleList(\n",
       "    (0): Compose(\n",
       "      (first): Convolution(\n",
       "        (sc): FullyConnectedTensorProduct(5x0e x 1x0e -> 336x0e+67x1o+40x2e+29x3o | 1680 paths | 1680 weights)\n",
       "        (lin1): FullyConnectedTensorProduct(5x0e x 1x0e -> 5x0e | 25 paths | 25 weights)\n",
       "        (fc): FullyConnectedNet[10, 128, 20]\n",
       "        (tp): TensorProduct(5x0e x 1x0e+1x1o+1x2e+1x3o -> 5x0e+5x1o+5x2e+5x3o | 20 paths | 20 weights)\n",
       "        (lin2): FullyConnectedTensorProduct(5x0e+5x1o+5x2e+5x3o x 1x0e -> 336x0e+67x1o+40x2e+29x3o | 2360 paths | 2360 weights)\n",
       "      )\n",
       "      (second): Gate (336x0e+67x1o+40x2e+29x3o -> 200x0e+67x1o+40x2e+29x3o)\n",
       "    )\n",
       "    (1): Compose(\n",
       "      (first): Convolution(\n",
       "        (sc): FullyConnectedTensorProduct(200x0e+67x1o+40x2e+29x3o x 1x0e -> 472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 101330 paths | 101330 weights)\n",
       "        (lin1): FullyConnectedTensorProduct(200x0e+67x1o+40x2e+29x3o x 1x0e -> 200x0e+67x1o+40x2e+29x3o | 46930 paths | 46930 weights)\n",
       "        (fc): FullyConnectedNet[10, 128, 2133]\n",
       "        (tp): TensorProduct(200x0e+67x1o+40x2e+29x3o x 1x0e+1x1o+1x2e+1x3o -> 336x0e+443x1o+136x1e+176x2o+472x2e+405x3o+165x3e | 2133 paths | 2133 weights)\n",
       "        (lin2): FullyConnectedTensorProduct(336x0e+443x1o+136x1e+176x2o+472x2e+405x3o+165x3e x 1x0e -> 472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 239835 paths | 239835 weights)\n",
       "      )\n",
       "      (second): Gate (472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e -> 200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e)\n",
       "    )\n",
       "    (2): Compose(\n",
       "      (first): Convolution(\n",
       "        (sc): FullyConnectedTensorProduct(200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e -> 200x0o+472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 108260 paths | 108260 weights)\n",
       "        (lin1): FullyConnectedTensorProduct(200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e -> 200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 53860 paths | 53860 weights)\n",
       "        (fc): FullyConnectedNet[10, 128, 3466]\n",
       "        (tp): TensorProduct(200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e+1x1o+1x2e+1x3o -> 136x0o+336x0e+579x1o+379x1e+448x2o+648x2e+570x3o+370x3e | 3466 paths | 3466 weights)\n",
       "        (lin2): FullyConnectedTensorProduct(136x0o+336x0e+579x1o+379x1e+448x2o+648x2e+570x3o+370x3e x 1x0e -> 200x0o+472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 321078 paths | 321078 weights)\n",
       "      )\n",
       "      (second): Gate (200x0o+472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e -> 200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e)\n",
       "    )\n",
       "    (3): Compose(\n",
       "      (first): Convolution(\n",
       "        (sc): FullyConnectedTensorProduct(200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e -> 200x0o+472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 148260 paths | 148260 weights)\n",
       "        (lin1): FullyConnectedTensorProduct(200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e -> 200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 93860 paths | 93860 weights)\n",
       "        (fc): FullyConnectedNet[10, 128, 4266]\n",
       "        (tp): TensorProduct(200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e+1x1o+1x2e+1x3o -> 336x0o+336x0e+579x1o+579x1e+648x2o+648x2e+570x3o+570x3e | 4266 paths | 4266 weights)\n",
       "        (lin2): FullyConnectedTensorProduct(336x0o+336x0e+579x1o+579x1e+648x2o+648x2e+570x3o+570x3e x 1x0e -> 200x0o+472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 388278 paths | 388278 weights)\n",
       "      )\n",
       "      (second): Gate (200x0o+472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e -> 200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e)\n",
       "    )\n",
       "    (4): Compose(\n",
       "      (first): Convolution(\n",
       "        (sc): FullyConnectedTensorProduct(200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e -> 200x0o+472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 148260 paths | 148260 weights)\n",
       "        (lin1): FullyConnectedTensorProduct(200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e -> 200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 93860 paths | 93860 weights)\n",
       "        (fc): FullyConnectedNet[10, 128, 4266]\n",
       "        (tp): TensorProduct(200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e+1x1o+1x2e+1x3o -> 336x0o+336x0e+579x1o+579x1e+648x2o+648x2e+570x3o+570x3e | 4266 paths | 4266 weights)\n",
       "        (lin2): FullyConnectedTensorProduct(336x0o+336x0e+579x1o+579x1e+648x2o+648x2e+570x3o+570x3e x 1x0e -> 200x0o+472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 388278 paths | 388278 weights)\n",
       "      )\n",
       "      (second): Gate (200x0o+472x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e -> 200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e)\n",
       "    )\n",
       "    (5): Convolution(\n",
       "      (sc): FullyConnectedTensorProduct(200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e -> 14x0e+5x1o+5x2e+2x3o+1x4e | 3393 paths | 3393 weights)\n",
       "      (lin1): FullyConnectedTensorProduct(200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e -> 200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e | 93860 paths | 93860 weights)\n",
       "      (fc): FullyConnectedNet[10, 128, 2367]\n",
       "      (tp): TensorProduct(200x0o+200x0e+67x1o+67x1e+40x2o+40x2e+29x3o+29x3e x 1x0e+1x1o+1x2e+1x3o -> 336x0e+579x1o+648x2e+570x3o+234x4e | 2367 paths | 2367 weights)\n",
       "      (lin2): FullyConnectedTensorProduct(336x0e+579x1o+648x2e+570x3o+234x4e x 1x0e -> 14x0e+5x1o+5x2e+2x3o+1x4e | 12213 paths | 12213 weights)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from e3nn.nn.models.gate_points_2101 import Network\n",
    "from e3nn import o3\n",
    "\n",
    "model_kwargs = {\n",
    "    \"irreps_in\": \"5x 0e\", #irreps_in \n",
    "    \"irreps_hidden\": [(mul, l, p) for l, mul in enumerate([200,67,40,29]) for p in [-1, 1]], #irreps_hidden\n",
    "    #\"irreps_hidden\": \"100x0e + 100x0o\",\n",
    "    \"irreps_out\": \"14x0e + 5x1o + 5x2e + 2x3o + 1x4e\", #irreps_out\n",
    "    \"irreps_node_attr\": None, #irreps_node_attr\n",
    "    \"irreps_edge_attr\": o3.Irreps.spherical_harmonics(3), #irreps_edge_attr\n",
    "    \"layers\": 5,\n",
    "    \"max_radius\": 3.5,\n",
    "    \"num_neighbors\": 12.666666,\n",
    "    \"number_of_basis\": 10,\n",
    "    \"radial_layers\": 1,\n",
    "    \"radial_neurons\": 128,\n",
    "    \"num_nodes\": 24,\n",
    "    \"reduce_output\": False,\n",
    "}\n",
    "\n",
    "model = Network(**model_kwargs)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "optim.zero_grad()\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('trainall-400.pkl')\n",
    "\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate density from CUBE file\n",
    "from utils import generate_grid, gau2grid_density_kdtree\n",
    "from ase.io.cube import read_cube\n",
    "\n",
    "num = 0\n",
    "\n",
    "data = loader.dataset[num]\n",
    "\n",
    "# run model on that sample\n",
    "mask = torch.where(data.y == 0, torch.zeros_like(data.y), torch.ones_like(data.y)).detach()\n",
    "y_ml = model(data.to(device))*mask.to(device)\n",
    "\n",
    "#get grid from cube file\n",
    "# ase converts all distances in cube file to angstroms\n",
    "f = open(\"./Dt-1.cube\", \"r\")\n",
    "\n",
    "cube_dict = read_cube(f)\n",
    "true_density = cube_dict['data']\n",
    "\n",
    "origin = cube_dict['origin'] #ang\n",
    "atoms = cube_dict['atoms']\n",
    "npts_x = true_density.shape[0]\n",
    "npts_y = true_density.shape[1]\n",
    "npts_z = true_density.shape[2]\n",
    "x_spacing = atoms.cell[0,0]/npts_x #assumes a rectangular grid\n",
    "y_spacing = atoms.cell[1,1]/npts_y #assumes a rectangular grid\n",
    "z_spacing = atoms.cell[2,2]/npts_z #assumes a rectangular grid\n",
    "xlin = np.linspace(origin[0], origin[0]+atoms.cell[0,0]-x_spacing, num=npts_x)\n",
    "ylin = np.linspace(origin[1], origin[1]+atoms.cell[1,1]-y_spacing, num=npts_y)\n",
    "zlin = np.linspace(origin[2], origin[2]+atoms.cell[2,2]-z_spacing, num=npts_z)\n",
    "\n",
    "x,y,z = np.meshgrid(xlin,ylin,zlin,indexing='ij')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate density on a grid for a random structure\n",
    "from utils import generate_grid, gau2grid_density_kdtree\n",
    "\n",
    "num = 0\n",
    "\n",
    "data = loader.dataset[num]\n",
    "\n",
    "# run model on that sample\n",
    "mask = torch.where(data.y == 0, torch.zeros_like(data.y), torch.ones_like(data.y)).detach()\n",
    "y_ml = model(data.to(device))*mask.to(device)\n",
    "\n",
    "x,y,z,vol,x_spacing,y_spacing,z_spacing = generate_grid(data,spacing=0.2,buffer=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small:  1e-05\n",
      "Read in: vol, x, y, z spacing 0.001185477689497923 0.10583544211276823 0.10583544211276824 0.10583544211276824\n",
      "Predicted: 580.9321883056722\n",
      "Target: 580.9037910464737\n",
      "True: 581.1240486346064\n",
      "\n",
      "ML - target eps:  0.6445035997098081\n",
      "Projection eps:  0.7891244693497593\n",
      "ML - true eps:  1.0725486813494987\n"
     ]
    }
   ],
   "source": [
    "Rs = [(14, 0), (5, 1), (5, 2), (2, 3), (1, 4)]\n",
    "\n",
    "target_density, ml_density = gau2grid_density_kdtree(x.flatten(),y.flatten(),z.flatten(),data,y_ml,Rs, isoOnlyFlag=0)\n",
    "\n",
    "angstrom2bohr = 1.8897259886\n",
    "vol = x_spacing * y_spacing * z_spacing\n",
    "print(\"Read in: vol, x, y, z spacing\", vol, x_spacing, y_spacing, z_spacing)\n",
    "\n",
    "num_ele_ml = np.sum(ml_density)*vol*angstrom2bohr**3\n",
    "num_ele_target = np.sum(target_density)*vol*angstrom2bohr**3\n",
    "num_ele_true = np.sum(true_density)*vol*angstrom2bohr**3\n",
    "print(\"Predicted:\", num_ele_ml)\n",
    "print(\"Target:\", num_ele_target)\n",
    "print(\"True:\", num_ele_true)\n",
    "print()\n",
    "\n",
    "ep_ml = 100 * np.sum(np.abs(ml_density.flatten()-target_density.flatten())) / np.sum(target_density.flatten())\n",
    "ep_project = 100 * np.sum(np.abs(target_density.flatten()-true_density.flatten())) / np.sum(true_density.flatten())\n",
    "ep_true = 100 * np.sum(np.abs(ml_density.flatten()-true_density.flatten())) / np.sum(true_density.flatten())\n",
    "print(\"ML - target eps: \",ep_ml)\n",
    "print(\"Projection eps: \",ep_project)\n",
    "print(\"ML - true eps: \",ep_true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out CUSTOM cube file\n",
    "from ase.io.cube import write_cube\n",
    "from ase.atoms import Atoms\n",
    "\n",
    "numbers_out = data.z.flatten().cpu().detach().numpy()\n",
    "pos_out = data.pos_orig.cpu().detach().numpy()\n",
    "cell_out = [atoms.cell[0,0], atoms.cell[1,1], atoms.cell[2,2]]\n",
    "#cell_out = [cell[0,0], cell[1,1], cell[2,2]]\n",
    "\n",
    "atoms_out = Atoms(numbers=numbers_out, positions=pos_out, cell=cell_out)\n",
    "\n",
    "target_out = target_density.reshape(x.shape)\n",
    "ml_out = ml_density.reshape(x.shape)\n",
    "\n",
    "#f_out = open(\"4mer.03.target.cube\", \"w\")\n",
    "#write_cube(f_out, atoms_out, data=target_out, origin=origin)\n",
    "\n",
    "f_out2 = open(\"2mertest-ml-0.cube\", \"w\")\n",
    "write_cube(f_out2, atoms_out, data=ml_out, origin=origin)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e3nn-env",
   "language": "python",
   "name": "e3nn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
